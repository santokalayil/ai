# LLM basic params:
- `temperature` and `top_p` are important parameters for controlling the randomness and creativity of text generated by Large Language Models (LLMs)
    - `temperature`
    - `top_p`

# LLM Cost/API call monitoring tools

- Pydantic AI's LogFire
- LangSmith by Langchain

# Validating LLM outputs
- There isn't a single "silver bullet" solution.
- Few Approaches
    - Use another LLM to validate outputs
    - Statistical Methods:
        - **BLEU** Score - for translation (Bilingual Evaluation Understudy) - Focuses on precision, may not capture recall
            - Breaks down both the generated text and the reference text(s) into n-grams (e.g., unigrams, bigrams, trigrams).
            - Counts the number of matching n-grams between the generated text and the reference text(s)
            - Calculates a precision score based on these counts.
            - Applies a brevity penalty to penalize generated text that is significantly shorter than the reference text(s).
            - 
            ```python
            from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

            reference = [['this', 'is', 'a', 'test'], ['this', 'is', 'another', 'test']]  # Multiple references are possible
            candidate = ['this', 'is', 'a', 'test']

            # Smoothing function to handle cases with zero counts
            smoothing = SmoothingFunction().method4

            score = sentence_bleu(reference, candidate, smoothing_function=smoothing)
            print(f"BLEU score: {score}")

            ########### LOGIC 2
            import sacrebleu

            reference = ["this is a test", "this is another test"]
            candidate = "this is a test"

            bleu = sacrebleu.metrics.BLEU()
            result = bleu.corpus_score([candidate], [reference]) # Note the list format for corpus score even with one sentence.
            print(result) # Includes the score and other helpful info.
            print(f"BLEU score: {result.score}")
            ```
        - **ROUGE** (Recall-Oriented Understudy for Gisting Evaluation) score - for summarization - focuses on the recall of the generated text. It assesses how much of the content in the reference text(s) is also present in the generated output.
            - Comes in different variations (ROUGE-N, ROUGE-L, ROUGE-S), each with a slightly different approach.   
            - ROUGE-N: Measures the overlap of **n-grams** between the generated text and the reference text(s).   
            - ROUGE-L: Measures the **longest** common subsequence between the generated text and the reference text(s).   
            - ROUGE-S: Measures the overlap of **skip-bigrams** (word pairs that can be separated by other words).

            ```python
            from rouge_score import rouge_scorer

            reference = "this is a test summary"
            candidate = "this is a test summary too"

            scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True) # rouge1 for unigrams, rougeL for longest common subsequence
            scores = scorer.score(reference, candidate)

            print(scores)
            print(f"ROUGE-1: {scores['rouge1'].fmeasure}")
            print(f"ROUGE-L: {scores['rougeL'].fmeasure}")
            ```



    - Manual Review
    - Rule-Based Systems (checking if special keywords are there)


# Validating Agentic AI
## Task Completion / Success Rate
**Definition:** Measures how effectively the agent accomplishes its assigned tasks or objectives.   

**Metrics:**
- Success Rate: Percentage of tasks successfully completed.
- Completion Time: Time taken to complete a task.
- Cost: Resources consumed during task completion (e.g., energy, computation).

## Quality of Decsions and Actions
**Definition:** Evaluates the quality of the agent's decision-making and actions in different situations.

**Metrics:**
- Accuracy: Correctness of the agent's decisions or actions.
- Efficiency: How efficiently the agent utilizes resources to achieve its goals.
- Robustness: Ability of the agent to handle unexpected situations or errors.
- Explainability: How well the agent can explain its decision-making process.

